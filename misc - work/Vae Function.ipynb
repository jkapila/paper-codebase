{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [ 2,  4,  6,  8, 10, 12, 14, 16, 18],\n",
       "       [ 3,  6,  9, 12, 15, 18, 21, 24, 27],\n",
       "       [ 4,  8, 12, 16, 20, 24, 28, 32, 36],\n",
       "       [ 5, 10, 15, 20, 25, 30, 35, 40, 45],\n",
       "       [ 6, 12, 18, 24, 30, 36, 42, 48, 54],\n",
       "       [ 7, 14, 21, 28, 35, 42, 49, 56, 63],\n",
       "       [ 8, 16, 24, 32, 40, 48, 56, 64, 72],\n",
       "       [ 9, 18, 27, 36, 45, 54, 63, 72, 81]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.outer(np.arange(1,10).reshape((3,3)),np.arange(1,10).reshape((3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 -1  1 -1 -1]\n",
      " [-1  1 -1  1  1]\n",
      " [ 1 -1  1 -1 -1]\n",
      " [-1  1 -1  1  1]\n",
      " [-1  1 -1  1  1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0, -1,  1, -1, -1],\n",
       "       [-1,  0, -1,  1,  1],\n",
       "       [ 1, -1,  0, -1, -1],\n",
       "       [-1,  1, -1,  0,  1],\n",
       "       [-1,  1, -1,  1,  0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.outer([1,-1,1,-1,-1],[1,-1,1,-1,-1])\n",
    "print(p)\n",
    "np.fill_diagonal(p,0)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HopfieldNet(object):\n",
    "\n",
    "    def __init__(self, num_units):\n",
    "        self.num_units = num_units\n",
    "        self.w = np.zeros((num_units, num_units))\n",
    "        self.b = np.zeros(num_units)\n",
    "\n",
    "    def store(self, data):\n",
    "        data = _data.reshape(data.shape[0], 1)\n",
    "        activations = np.dot(data, data.T)\n",
    "        np.fill_diagonal(activations, 0)  # because there are no connections to itself\n",
    "        self.w += activations\n",
    "        self.b += data.ravel()\n",
    "\n",
    "    def get_energy(self, data):\n",
    "        # first let's again compute product of activations\n",
    "        data = _data.reshape(data.shape[0], 1)\n",
    "        activations = np.float32(np.dot(data, data.T))\n",
    "        np.fill_diagonal(activations, 0)\n",
    "        # then multiply each activation by a weight elementwise\n",
    "        activations *= self.w\n",
    "        # total energy consists of weight and bias term\n",
    "        weight_term = np.sum(activations) / 2  # divide by 2, because we've counted neurons twice\n",
    "        bias_term = np.dot(self.b, data)[0]\n",
    "        return - bias_term - weight_term\n",
    "    \n",
    "    def restore(self, data):\n",
    "        data = np.copy(_data)\n",
    "        idx = range(len(data))\n",
    "        # make 10 passes through the data\n",
    "        for i in xrange(10):\n",
    "            for _ in xrange(len(data)):\n",
    "                j = np.random.choice(idx)\n",
    "                inputs = np.sum(data * self.w[j])\n",
    "                if inputs > 0:\n",
    "                    data[j] = 1\n",
    "                else:\n",
    "                    data[j] = -1\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Input, Lambda\n",
    "from keras.models import Model,Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import backend as K\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_feature_generation(data,components='auto',funnel=(2.5,9),\n",
    "                           batch=200,epoch = 250,epsilon=1.0,opt= None,\n",
    "                           validation=False, plot_it=False):\n",
    "    \n",
    "    original_dim = data.shape[1]\n",
    "\n",
    "    if components == 'auto':\n",
    "        intermediate_dim = int(np.ceil(original_dim/2.5))\n",
    "        latent_dim = int(np.ceil(intermediate_dim/9))\n",
    "    elif components == 'ratio':\n",
    "        intermediate_dim = int(np.ceil(original_dim/funnel[0]))\n",
    "        latent_dim = int(np.ceil(intermediate_dim/funnel[1]))\n",
    "    elif components == 'values':\n",
    "        intermediate_dim = funnel[0]\n",
    "        latent_dim = funnel[1]\n",
    "    \n",
    "    batch_size = batch\n",
    "    epochs = epoch\n",
    "    epsilon_std = epsilon\n",
    "\n",
    "    x = Input(shape = (original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='elu')(x)\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                                  stddev=epsilon_std)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "    # we instantiate these layers separately so as to reuse them later\n",
    "    decoder_h = Dense(intermediate_dim, activation='elu')\n",
    "    decoder_mean = Dense(original_dim, activation='relu')\n",
    "    h_decoded = decoder_h(z)\n",
    "    x_decoded_mean = decoder_mean(h_decoded)\n",
    "    \n",
    "    # instantiate VAE model\n",
    "    vae = Model(inputs=x, outputs=x_decoded_mean)\n",
    "\n",
    "    # Compute VAE loss\n",
    "    xent_loss = original_dim * metrics.mean_squared_error(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    vae.add_loss(vae_loss)\n",
    "    if opt is None:\n",
    "        opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "    vae.compile(optimizer=opt)\n",
    "    vae.summary()\n",
    "    \n",
    "    # fitting our generated features on the data\n",
    "    vae.fit(data,\n",
    "            shuffle=True,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size\n",
    "    #         validation_data=(x_test, None)\n",
    "           )\n",
    "    \n",
    "    # Encoder model for feature generation\n",
    "    encoder = Model(inputs=x, outputs = z_mean)\n",
    "\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    tr = encoder.predict(data, batch_size=batch_size)\n",
    "    if plot_it:\n",
    "        print('\\nPlotting features!\\n')\n",
    "        # Plotting with SNS\n",
    "        sns.set(style=\"ticks\")\n",
    "        df_plot = pd.DataFrame(tr)\n",
    "        g = sns.PairGrid(df_plot)\n",
    "        g = g.map_upper(plt.scatter)\n",
    "        g = g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "        g = g.map_diag(sns.kdeplot, lw=3, legend=False)\n",
    "        g\n",
    "        \n",
    "    return tr, latent_dim, encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.054000           3.758667   \n",
       "std             0.828066          0.433594           1.764420   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.198667    1.000000  \n",
       "std            0.763161    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris()\n",
    "df  = pd.concat([pd.DataFrame(data.data),pd.DataFrame(data.target)],axis = 1)\n",
    "data.feature_names.append('target')\n",
    "df.columns = data.feature_names\n",
    "print(df.head())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.2\n",
       "1    0.2\n",
       "2    0.2\n",
       "3    0.2\n",
       "Name: petal width (cm), dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:4,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jitins_lab/anaconda2/envs/hyper/lib/python3.6/site-packages/ipykernel/__main__.py:53: UserWarning: Output \"dense_30\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_30\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 20)           100         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 2)            42          dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 2)            42          dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 2)            0           dense_27[0][0]                   \n",
      "                                                                 dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 20)           60          lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 4)            84          dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 328\n",
      "Trainable params: 328\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 58.6861\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 27us/step - loss: 55.0059\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 29us/step - loss: 49.9570\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 36us/step - loss: 44.7771\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 35us/step - loss: 38.8098\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 27us/step - loss: 32.3060\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 38us/step - loss: 28.7598\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 39us/step - loss: 25.7699\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 34us/step - loss: 24.4947\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 32us/step - loss: 22.6655\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 32us/step - loss: 20.8131\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 35us/step - loss: 18.6003\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 41us/step - loss: 16.7936\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 33us/step - loss: 15.1943\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 30us/step - loss: 14.0555\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 32us/step - loss: 12.6159\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 46us/step - loss: 11.5589\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 40us/step - loss: 10.7486\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 45us/step - loss: 9.9526\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 62us/step - loss: 9.6961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[  2.03996205e+00,  -4.29239750e-01],\n",
       "        [  1.96641374e+00,  -4.00960177e-01],\n",
       "        [  1.85129476e+00,  -4.32687491e-01],\n",
       "        [  1.82796276e+00,  -3.71154815e-01],\n",
       "        [  1.98720014e+00,  -4.30590540e-01],\n",
       "        [  2.21718717e+00,  -4.18170601e-01],\n",
       "        [  1.81141949e+00,  -4.32150632e-01],\n",
       "        [  2.00577116e+00,  -3.95570070e-01],\n",
       "        [  1.73306429e+00,  -3.83179754e-01],\n",
       "        [  1.96086860e+00,  -3.57192546e-01],\n",
       "        [  2.18510985e+00,  -4.18821007e-01],\n",
       "        [  1.91845453e+00,  -3.63307297e-01],\n",
       "        [  1.90867829e+00,  -3.76680672e-01],\n",
       "        [  1.63708973e+00,  -4.46803421e-01],\n",
       "        [  2.33702159e+00,  -5.20943105e-01],\n",
       "        [  2.32602048e+00,  -4.96995658e-01],\n",
       "        [  2.17945790e+00,  -5.24488389e-01],\n",
       "        [  2.05036569e+00,  -4.51263934e-01],\n",
       "        [  2.35281157e+00,  -4.00747567e-01],\n",
       "        [  2.04662704e+00,  -4.36110109e-01],\n",
       "        [  2.21344256e+00,  -3.53012174e-01],\n",
       "        [  2.06154585e+00,  -4.54215556e-01],\n",
       "        [  1.74763107e+00,  -5.29038250e-01],\n",
       "        [  2.10877109e+00,  -4.06886429e-01],\n",
       "        [  1.94482327e+00,  -2.84952998e-01],\n",
       "        [  2.03224325e+00,  -3.49955887e-01],\n",
       "        [  2.03633666e+00,  -4.12710518e-01],\n",
       "        [  2.09727883e+00,  -4.05150801e-01],\n",
       "        [  2.09175730e+00,  -4.27267402e-01],\n",
       "        [  1.88030434e+00,  -3.51838142e-01],\n",
       "        [  1.93327427e+00,  -3.50085467e-01],\n",
       "        [  2.21721196e+00,  -4.50037211e-01],\n",
       "        [  2.06161499e+00,  -4.06228006e-01],\n",
       "        [  2.20568132e+00,  -4.67015773e-01],\n",
       "        [  1.96086860e+00,  -3.57192546e-01],\n",
       "        [  1.98497999e+00,  -4.67583984e-01],\n",
       "        [  2.22016954e+00,  -4.65194851e-01],\n",
       "        [  1.96086860e+00,  -3.57192546e-01],\n",
       "        [  1.71688724e+00,  -4.15221900e-01],\n",
       "        [  2.05362964e+00,  -3.98184955e-01],\n",
       "        [  1.99210691e+00,  -4.75574166e-01],\n",
       "        [  1.81465435e+00,  -4.01873082e-01],\n",
       "        [  1.70452619e+00,  -4.23748434e-01],\n",
       "        [  2.05268359e+00,  -4.60213214e-01],\n",
       "        [  2.09290767e+00,  -3.52819413e-01],\n",
       "        [  1.92956781e+00,  -4.20651287e-01],\n",
       "        [  2.04545569e+00,  -3.87940317e-01],\n",
       "        [  1.81274188e+00,  -4.02551323e-01],\n",
       "        [  2.13730288e+00,  -4.16222006e-01],\n",
       "        [  2.00065327e+00,  -4.17867959e-01],\n",
       "        [  3.31453085e+00,   4.12902273e-02],\n",
       "        [  3.04104066e+00,   8.41194764e-03],\n",
       "        [  3.30411696e+00,   6.67530298e-02],\n",
       "        [  2.62951446e+00,  -4.71979007e-03],\n",
       "        [  3.11934423e+00,   2.58319117e-02],\n",
       "        [  2.72184205e+00,   8.55816901e-02],\n",
       "        [  3.01681113e+00,   3.64868082e-02],\n",
       "        [  2.25047183e+00,  -6.91135228e-02],\n",
       "        [  3.13167405e+00,   5.97485341e-02],\n",
       "        [  2.46580386e+00,  -3.53284441e-02],\n",
       "        [  2.34640908e+00,  -2.08348893e-02],\n",
       "        [  2.80266118e+00,  -2.97594033e-02],\n",
       "        [  2.82306361e+00,   3.10570337e-02],\n",
       "        [  2.92598557e+00,   8.62893462e-02],\n",
       "        [  2.60207629e+00,  -1.09153181e-01],\n",
       "        [  3.16195893e+00,  -6.15778193e-03],\n",
       "        [  2.68634987e+00,   5.23223914e-02],\n",
       "        [  2.70376849e+00,   5.57031967e-02],\n",
       "        [  3.02423596e+00,   1.92606784e-02],\n",
       "        [  2.62383676e+00,   6.29401579e-03],\n",
       "        [  2.87159801e+00,   4.28967215e-02],\n",
       "        [  2.86406922e+00,  -3.96320187e-02],\n",
       "        [  3.07988000e+00,   9.23747420e-02],\n",
       "        [  2.90795875e+00,   1.23512626e-01],\n",
       "        [  3.01718092e+00,   8.40995088e-03],\n",
       "        [  3.12240243e+00,  -7.23507255e-04],\n",
       "        [  3.25858402e+00,   6.93433285e-02],\n",
       "        [  3.25453091e+00,   5.85194267e-02],\n",
       "        [  2.87744308e+00,   3.10762264e-02],\n",
       "        [  2.61646390e+00,  -6.48775399e-02],\n",
       "        [  2.57764030e+00,  -8.42684135e-03],\n",
       "        [  2.55608106e+00,  -9.54267010e-03],\n",
       "        [  2.71351886e+00,  -2.57538222e-02],\n",
       "        [  2.95705247e+00,   1.33717924e-01],\n",
       "        [  2.59338522e+00,   6.36786222e-02],\n",
       "        [  2.85977221e+00,   5.73286787e-03],\n",
       "        [  3.19792962e+00,   3.62665989e-02],\n",
       "        [  3.02468848e+00,   3.42156328e-02],\n",
       "        [  2.63145518e+00,   2.32759491e-03],\n",
       "        [  2.61305952e+00,  -6.68033585e-03],\n",
       "        [  2.62575698e+00,   9.48609114e-02],\n",
       "        [  2.91086841e+00,   6.56189620e-02],\n",
       "        [  2.72838426e+00,  -3.17877159e-03],\n",
       "        [  2.30328822e+00,  -7.06833899e-02],\n",
       "        [  2.65963769e+00,   2.83903219e-02],\n",
       "        [  2.67162251e+00,   3.91630568e-02],\n",
       "        [  2.69112706e+00,   2.10274793e-02],\n",
       "        [  2.92669177e+00,   1.77323557e-02],\n",
       "        [  2.32430077e+00,  -1.71717048e-01],\n",
       "        [  2.69021606e+00,   7.16004521e-04],\n",
       "        [  3.22988772e+00,   1.49857134e-01],\n",
       "        [  2.90514159e+00,   9.30246115e-02],\n",
       "        [  3.56440878e+00,   1.37813210e-01],\n",
       "        [  3.14482951e+00,   1.81551903e-01],\n",
       "        [  3.29579616e+00,   1.40394986e-01],\n",
       "        [  3.85515189e+00,   2.34356731e-01],\n",
       "        [  2.43468332e+00,   6.21158220e-02],\n",
       "        [  3.66288137e+00,   2.47388810e-01],\n",
       "        [  3.38432789e+00,   1.80689961e-01],\n",
       "        [  3.62856054e+00,   1.16116285e-01],\n",
       "        [  3.19623780e+00,   3.56137492e-02],\n",
       "        [  3.19528890e+00,   9.42902565e-02],\n",
       "        [  3.39359546e+00,   7.88856745e-02],\n",
       "        [  2.88455129e+00,   5.93554415e-02],\n",
       "        [  2.96179628e+00,   5.36230579e-03],\n",
       "        [  3.20472360e+00,   2.88754143e-02],\n",
       "        [  3.21829152e+00,   1.51436597e-01],\n",
       "        [  3.85114765e+00,   2.63524771e-01],\n",
       "        [  3.99696898e+00,   2.25713074e-01],\n",
       "        [  2.98415208e+00,   1.23340815e-01],\n",
       "        [  3.46527267e+00,   8.08606148e-02],\n",
       "        [  2.79990864e+00,   4.72313501e-02],\n",
       "        [  3.91734910e+00,   2.52404451e-01],\n",
       "        [  3.10154080e+00,   3.95613946e-02],\n",
       "        [  3.33966637e+00,   1.31373107e-01],\n",
       "        [  3.56286073e+00,   2.09972829e-01],\n",
       "        [  3.03952694e+00,   2.58320011e-02],\n",
       "        [  2.98623562e+00,   5.32824136e-02],\n",
       "        [  3.23893929e+00,   1.19956404e-01],\n",
       "        [  3.53687167e+00,   2.01973349e-01],\n",
       "        [  3.71106601e+00,   1.83817029e-01],\n",
       "        [  3.89323092e+00,   2.27304608e-01],\n",
       "        [  3.25206280e+00,   1.02535278e-01],\n",
       "        [  3.07153201e+00,   1.35450959e-01],\n",
       "        [  3.03265834e+00,   2.55775213e-01],\n",
       "        [  3.87892294e+00,   1.02079898e-01],\n",
       "        [  3.17738223e+00,   8.31056833e-02],\n",
       "        [  3.16390157e+00,   1.59737587e-01],\n",
       "        [  2.93257236e+00,   3.78899910e-02],\n",
       "        [  3.42261052e+00,   5.45687117e-02],\n",
       "        [  3.38725066e+00,   5.35438992e-02],\n",
       "        [  3.42494512e+00,  -4.41730879e-02],\n",
       "        [  2.90514159e+00,   9.30246115e-02],\n",
       "        [  3.43604326e+00,   1.27812415e-01],\n",
       "        [  3.39156580e+00,   5.95894791e-02],\n",
       "        [  3.34955144e+00,  -1.22410022e-02],\n",
       "        [  3.14139295e+00,   3.85254361e-02],\n",
       "        [  3.21915770e+00,   5.49062528e-02],\n",
       "        [  3.10345840e+00,   6.37752712e-02],\n",
       "        [  2.91004515e+00,   1.07507885e-01]], dtype=float32),\n",
       " 2,\n",
       " <keras.engine.training.Model at 0x1a1f621080>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_feature_generation(df.iloc[:,0:4],components='values',funnel=(20,2),epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jitins_lab/Documents/work/demo_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_days_membership</th>\n",
       "      <th>no_days_last_seen</th>\n",
       "      <th>email_levels_aol.com</th>\n",
       "      <th>email_levels_comcast.net</th>\n",
       "      <th>email_levels_gmail.com</th>\n",
       "      <th>email_levels_hotmail.com</th>\n",
       "      <th>email_levels_mail.house.gov</th>\n",
       "      <th>email_levels_others</th>\n",
       "      <th>email_levels_yahoo.com</th>\n",
       "      <th>browser_Chrome</th>\n",
       "      <th>...</th>\n",
       "      <th>region_DC</th>\n",
       "      <th>region_FL</th>\n",
       "      <th>region_IL</th>\n",
       "      <th>region_MD</th>\n",
       "      <th>region_NY</th>\n",
       "      <th>region_PA</th>\n",
       "      <th>region_TX</th>\n",
       "      <th>region_VA</th>\n",
       "      <th>region_others</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>514</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>514</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>514</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_days_membership  no_days_last_seen  email_levels_aol.com  \\\n",
       "0                  53                 36                     0   \n",
       "1                 514                 39                     0   \n",
       "2                 514                 39                     0   \n",
       "3                 199                 36                     0   \n",
       "4                 514                 47                     0   \n",
       "\n",
       "   email_levels_comcast.net  email_levels_gmail.com  email_levels_hotmail.com  \\\n",
       "0                         0                       1                         0   \n",
       "1                         0                       0                         0   \n",
       "2                         0                       0                         0   \n",
       "3                         0                       0                         0   \n",
       "4                         0                       0                         0   \n",
       "\n",
       "   email_levels_mail.house.gov  email_levels_others  email_levels_yahoo.com  \\\n",
       "0                            0                    0                       0   \n",
       "1                            1                    0                       0   \n",
       "2                            0                    1                       0   \n",
       "3                            0                    1                       0   \n",
       "4                            1                    0                       0   \n",
       "\n",
       "   browser_Chrome    ...     region_DC  region_FL  region_IL  region_MD  \\\n",
       "0               1    ...             0          0          1          0   \n",
       "1               0    ...             1          0          0          0   \n",
       "2               1    ...             0          0          0          0   \n",
       "3               0    ...             0          0          0          1   \n",
       "4               0    ...             1          0          0          0   \n",
       "\n",
       "   region_NY  region_PA  region_TX  region_VA  region_others  clusters  \n",
       "0          0          0          0          0              0         2  \n",
       "1          0          0          0          0              0         0  \n",
       "2          1          0          0          0              0         0  \n",
       "3          0          0          0          0              0         7  \n",
       "4          0          0          0          0              0         0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jitins_lab/anaconda2/envs/hyper/lib/python3.6/site-packages/ipykernel/__main__.py:53: UserWarning: Output \"dense_60\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_60\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 20)           820         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 5)            105         dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 5)            105         dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 5)            0           dense_57[0][0]                   \n",
      "                                                                 dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 20)           120         lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 40)           840         dense_59[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,990\n",
      "Trainable params: 1,990\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "10100/10100 [==============================] - 1s 77us/step - loss: 9.1691\n",
      "Epoch 2/20\n",
      "10100/10100 [==============================] - 0s 19us/step - loss: 5.5043\n",
      "Epoch 3/20\n",
      "10100/10100 [==============================] - 0s 18us/step - loss: 5.3739\n",
      "Epoch 4/20\n",
      "10100/10100 [==============================] - 0s 19us/step - loss: 5.3053\n",
      "Epoch 5/20\n",
      "10100/10100 [==============================] - 0s 20us/step - loss: 5.2732\n",
      "Epoch 6/20\n",
      "10100/10100 [==============================] - 0s 19us/step - loss: 5.2374\n",
      "Epoch 7/20\n",
      "10100/10100 [==============================] - 0s 18us/step - loss: 5.1949\n",
      "Epoch 8/20\n",
      "10100/10100 [==============================] - 0s 22us/step - loss: 5.1827\n",
      "Epoch 9/20\n",
      "10100/10100 [==============================] - 0s 23us/step - loss: 5.1849\n",
      "Epoch 10/20\n",
      "10100/10100 [==============================] - 0s 24us/step - loss: 5.1895\n",
      "Epoch 11/20\n",
      "10100/10100 [==============================] - 0s 24us/step - loss: 5.1783\n",
      "Epoch 12/20\n",
      "10100/10100 [==============================] - 0s 21us/step - loss: 5.1610\n",
      "Epoch 13/20\n",
      "10100/10100 [==============================] - 0s 19us/step - loss: 5.1608\n",
      "Epoch 14/20\n",
      "10100/10100 [==============================] - 0s 20us/step - loss: 5.1590\n",
      "Epoch 15/20\n",
      "10100/10100 [==============================] - 0s 19us/step - loss: 5.1394\n",
      "Epoch 16/20\n",
      "10100/10100 [==============================] - 0s 20us/step - loss: 5.1484\n",
      "Epoch 17/20\n",
      "10100/10100 [==============================] - 0s 22us/step - loss: 5.1513\n",
      "Epoch 18/20\n",
      "10100/10100 [==============================] - 0s 19us/step - loss: 5.1285\n",
      "Epoch 19/20\n",
      "10100/10100 [==============================] - 0s 19us/step - loss: 5.1650\n",
      "Epoch 20/20\n",
      "10100/10100 [==============================] - 0s 19us/step - loss: 5.1406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.1406091 , -0.06560794, -0.44563228,  0.40716445,  0.18203133],\n",
       "        [-0.96386069, -0.04932985, -0.0777006 , -1.4933871 , -0.06372079],\n",
       "        [ 0.96305639,  0.04226241,  0.09615929, -0.42803565,  0.04171118],\n",
       "        ..., \n",
       "        [-0.81237823, -0.03154868,  0.06155227,  0.42499986, -0.01237265],\n",
       "        [-1.10280693,  0.02248526,  0.05725055,  0.41712466, -0.05142437],\n",
       "        [-0.98738986, -0.0550078 , -0.03147643, -1.26622903, -0.07907742]], dtype=float32),\n",
       " 5,\n",
       " <keras.engine.training.Model at 0x1a21a23d68>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_feature_generation(df.iloc[:,2:],components='values',funnel=(20,5),epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no_days_membership</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>393.572970</td>\n",
       "      <td>161.142717</td>\n",
       "      <td>35.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_days_last_seen</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>41.587327</td>\n",
       "      <td>8.196698</td>\n",
       "      <td>34.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_levels_aol.com</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.039901</td>\n",
       "      <td>0.195736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_levels_comcast.net</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.155378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_levels_gmail.com</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.251287</td>\n",
       "      <td>0.433775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_levels_hotmail.com</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.031089</td>\n",
       "      <td>0.173567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_levels_mail.house.gov</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.139802</td>\n",
       "      <td>0.346799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_levels_others</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.450495</td>\n",
       "      <td>0.497568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_levels_yahoo.com</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.062673</td>\n",
       "      <td>0.242386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>browser_Chrome</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.251782</td>\n",
       "      <td>0.434058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>browser_Chrome Mobile</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.087426</td>\n",
       "      <td>0.282472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>browser_Edge</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.051386</td>\n",
       "      <td>0.220795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>browser_Firefox</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.054653</td>\n",
       "      <td>0.227314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>browser_IE</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.086634</td>\n",
       "      <td>0.281311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>browser_Mobile Safari</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.478970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>browser_Safari</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.052376</td>\n",
       "      <td>0.222796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>browser_others</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.059307</td>\n",
       "      <td>0.236210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_Alexandria</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.027129</td>\n",
       "      <td>0.162466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_Washington</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.279307</td>\n",
       "      <td>0.448681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_others</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.693564</td>\n",
       "      <td>0.461036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country_US</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.975050</td>\n",
       "      <td>0.155982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country_others</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.024950</td>\n",
       "      <td>0.155982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_type_PC</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.492277</td>\n",
       "      <td>0.499965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_type_iPad</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.069406</td>\n",
       "      <td>0.254156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_type_iPhone</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.311188</td>\n",
       "      <td>0.463002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_type_others</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.127129</td>\n",
       "      <td>0.333134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operating_system_Android</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.125248</td>\n",
       "      <td>0.331016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operating_system_Mac OS X</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.094851</td>\n",
       "      <td>0.293024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operating_system_Windows</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.380297</td>\n",
       "      <td>0.485484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operating_system_iOS</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.380792</td>\n",
       "      <td>0.485606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operating_system_others</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.018812</td>\n",
       "      <td>0.135867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_CA</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.067030</td>\n",
       "      <td>0.250086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_DC</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.272277</td>\n",
       "      <td>0.445154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_FL</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.033663</td>\n",
       "      <td>0.180370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_IL</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.024851</td>\n",
       "      <td>0.155680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_MD</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.074158</td>\n",
       "      <td>0.262041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_NY</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.042277</td>\n",
       "      <td>0.201231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_PA</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.034356</td>\n",
       "      <td>0.182152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_TX</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.037921</td>\n",
       "      <td>0.191014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_VA</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.099505</td>\n",
       "      <td>0.299354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_others</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>0.313960</td>\n",
       "      <td>0.464123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clusters</th>\n",
       "      <td>10100.0</td>\n",
       "      <td>1.631881</td>\n",
       "      <td>2.316166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count        mean         std   min    25%  \\\n",
       "no_days_membership           10100.0  393.572970  161.142717  35.0  259.0   \n",
       "no_days_last_seen            10100.0   41.587327    8.196698  34.0   39.0   \n",
       "email_levels_aol.com         10100.0    0.039901    0.195736   0.0    0.0   \n",
       "email_levels_comcast.net     10100.0    0.024752    0.155378   0.0    0.0   \n",
       "email_levels_gmail.com       10100.0    0.251287    0.433775   0.0    0.0   \n",
       "email_levels_hotmail.com     10100.0    0.031089    0.173567   0.0    0.0   \n",
       "email_levels_mail.house.gov  10100.0    0.139802    0.346799   0.0    0.0   \n",
       "email_levels_others          10100.0    0.450495    0.497568   0.0    0.0   \n",
       "email_levels_yahoo.com       10100.0    0.062673    0.242386   0.0    0.0   \n",
       "browser_Chrome               10100.0    0.251782    0.434058   0.0    0.0   \n",
       "browser_Chrome Mobile        10100.0    0.087426    0.282472   0.0    0.0   \n",
       "browser_Edge                 10100.0    0.051386    0.220795   0.0    0.0   \n",
       "browser_Firefox              10100.0    0.054653    0.227314   0.0    0.0   \n",
       "browser_IE                   10100.0    0.086634    0.281311   0.0    0.0   \n",
       "browser_Mobile Safari        10100.0    0.356436    0.478970   0.0    0.0   \n",
       "browser_Safari               10100.0    0.052376    0.222796   0.0    0.0   \n",
       "browser_others               10100.0    0.059307    0.236210   0.0    0.0   \n",
       "city_Alexandria              10100.0    0.027129    0.162466   0.0    0.0   \n",
       "city_Washington              10100.0    0.279307    0.448681   0.0    0.0   \n",
       "city_others                  10100.0    0.693564    0.461036   0.0    0.0   \n",
       "country_US                   10100.0    0.975050    0.155982   0.0    1.0   \n",
       "country_others               10100.0    0.024950    0.155982   0.0    0.0   \n",
       "device_type_PC               10100.0    0.492277    0.499965   0.0    0.0   \n",
       "device_type_iPad             10100.0    0.069406    0.254156   0.0    0.0   \n",
       "device_type_iPhone           10100.0    0.311188    0.463002   0.0    0.0   \n",
       "device_type_others           10100.0    0.127129    0.333134   0.0    0.0   \n",
       "operating_system_Android     10100.0    0.125248    0.331016   0.0    0.0   \n",
       "operating_system_Mac OS X    10100.0    0.094851    0.293024   0.0    0.0   \n",
       "operating_system_Windows     10100.0    0.380297    0.485484   0.0    0.0   \n",
       "operating_system_iOS         10100.0    0.380792    0.485606   0.0    0.0   \n",
       "operating_system_others      10100.0    0.018812    0.135867   0.0    0.0   \n",
       "region_CA                    10100.0    0.067030    0.250086   0.0    0.0   \n",
       "region_DC                    10100.0    0.272277    0.445154   0.0    0.0   \n",
       "region_FL                    10100.0    0.033663    0.180370   0.0    0.0   \n",
       "region_IL                    10100.0    0.024851    0.155680   0.0    0.0   \n",
       "region_MD                    10100.0    0.074158    0.262041   0.0    0.0   \n",
       "region_NY                    10100.0    0.042277    0.201231   0.0    0.0   \n",
       "region_PA                    10100.0    0.034356    0.182152   0.0    0.0   \n",
       "region_TX                    10100.0    0.037921    0.191014   0.0    0.0   \n",
       "region_VA                    10100.0    0.099505    0.299354   0.0    0.0   \n",
       "region_others                10100.0    0.313960    0.464123   0.0    0.0   \n",
       "clusters                     10100.0    1.631881    2.316166   0.0    0.0   \n",
       "\n",
       "                               50%    75%    max  \n",
       "no_days_membership           514.0  514.0  543.0  \n",
       "no_days_last_seen             40.0   45.0  391.0  \n",
       "email_levels_aol.com           0.0    0.0    1.0  \n",
       "email_levels_comcast.net       0.0    0.0    1.0  \n",
       "email_levels_gmail.com         0.0    1.0    1.0  \n",
       "email_levels_hotmail.com       0.0    0.0    1.0  \n",
       "email_levels_mail.house.gov    0.0    0.0    1.0  \n",
       "email_levels_others            0.0    1.0    1.0  \n",
       "email_levels_yahoo.com         0.0    0.0    1.0  \n",
       "browser_Chrome                 0.0    1.0    1.0  \n",
       "browser_Chrome Mobile          0.0    0.0    1.0  \n",
       "browser_Edge                   0.0    0.0    1.0  \n",
       "browser_Firefox                0.0    0.0    1.0  \n",
       "browser_IE                     0.0    0.0    1.0  \n",
       "browser_Mobile Safari          0.0    1.0    1.0  \n",
       "browser_Safari                 0.0    0.0    1.0  \n",
       "browser_others                 0.0    0.0    1.0  \n",
       "city_Alexandria                0.0    0.0    1.0  \n",
       "city_Washington                0.0    1.0    1.0  \n",
       "city_others                    1.0    1.0    1.0  \n",
       "country_US                     1.0    1.0    1.0  \n",
       "country_others                 0.0    0.0    1.0  \n",
       "device_type_PC                 0.0    1.0    1.0  \n",
       "device_type_iPad               0.0    0.0    1.0  \n",
       "device_type_iPhone             0.0    1.0    1.0  \n",
       "device_type_others             0.0    0.0    1.0  \n",
       "operating_system_Android       0.0    0.0    1.0  \n",
       "operating_system_Mac OS X      0.0    0.0    1.0  \n",
       "operating_system_Windows       0.0    1.0    1.0  \n",
       "operating_system_iOS           0.0    1.0    1.0  \n",
       "operating_system_others        0.0    0.0    1.0  \n",
       "region_CA                      0.0    0.0    1.0  \n",
       "region_DC                      0.0    1.0    1.0  \n",
       "region_FL                      0.0    0.0    1.0  \n",
       "region_IL                      0.0    0.0    1.0  \n",
       "region_MD                      0.0    0.0    1.0  \n",
       "region_NY                      0.0    0.0    1.0  \n",
       "region_PA                      0.0    0.0    1.0  \n",
       "region_TX                      0.0    0.0    1.0  \n",
       "region_VA                      0.0    0.0    1.0  \n",
       "region_others                  0.0    1.0    1.0  \n",
       "clusters                       0.0    3.0    8.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_feature_generation(data,components='auto',funnel=(45,30,15,10),\n",
    "                           batch=200,epoch = 250,epsilon=1.0,opt= None,\n",
    "                           validation=False, plot_it=False):\n",
    "    \n",
    "    original_dim = data.shape[1]\n",
    "\n",
    "    if components == 'auto':\n",
    "        intermediate_dim_1 = 45\n",
    "        intermediate_dim_2 = 30\n",
    "#         intermediate_dim_3 = 15\n",
    "        latent_dim = 10\n",
    "    elif components == 'ratio':\n",
    "        intermediate_dim_1 = int(np.ceil(original_dim/funnel[0]))\n",
    "        intermediate_dim_2 = int(np.ceil(original_dim/funnel[1]))\n",
    "#         intermediate_dim_3 = int(np.ceil(original_dim/funnel[2]))\n",
    "        latent_dim = int(np.ceil(intermediate_dim/funnel[3]))\n",
    "    elif components == 'values':\n",
    "        intermediate_dim_1 = funnel[0]\n",
    "        intermediate_dim_2 = funnel[1]\n",
    "#         intermediate_dim_3 = funnel[2]\n",
    "        latent_dim = funnel[3]\n",
    "    \n",
    "    batch_size = batch\n",
    "    epochs = epoch\n",
    "    epsilon_std = epsilon\n",
    "\n",
    "    x = Input(shape = (original_dim,))\n",
    "    h_1 = Dense(intermediate_dim_1, activation='elu')(x)\n",
    "    h_2 = Dense(intermediate_dim_2, activation='elu')(h_1)\n",
    "#     h_3 = Dense(intermediate_dim_3, activation='elu')(h_1)\n",
    "    z_mean = Dense(latent_dim)(h_2)\n",
    "    z_log_var = Dense(latent_dim)(h_2)\n",
    "\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                                  stddev=epsilon_std)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "    # we instantiate these layers separately so as to reuse them later\n",
    "    decoder_h_2 = Dense(intermediate_dim_2, activation='elu')\n",
    "    decoder_h_1 = Dense(intermediate_dim_1, activation='elu')\n",
    "    decoder_mean = Dense(original_dim, activation='relu')\n",
    "    h_decoded_2 = decoder_h_2(z)\n",
    "    h_decoded_1 = decoder_h_1(h_decoded_2)\n",
    "    x_decoded_mean = decoder_mean(h_decoded_1)\n",
    "    \n",
    "    # instantiate VAE model\n",
    "    vae = Model(inputs=x, outputs=x_decoded_mean)\n",
    "\n",
    "    # Compute VAE loss\n",
    "    xent_loss = original_dim * metrics.mean_squared_error(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    vae.add_loss(vae_loss)\n",
    "    if opt is None:\n",
    "        opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "    vae.compile(optimizer=opt)\n",
    "    vae.summary()\n",
    "    \n",
    "    # fitting our generated features on the data\n",
    "    vae.fit(data,\n",
    "            shuffle=True,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size\n",
    "    #         validation_data=(x_test, None)\n",
    "           )\n",
    "    \n",
    "    # Encoder model for feature generation\n",
    "    encoder = Model(inputs=x, outputs = z_mean)\n",
    "\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    tr = encoder.predict(data, batch_size=batch_size)\n",
    "    if plot_it:\n",
    "        print('\\nPlotting features!\\n')\n",
    "        # Plotting with SNS\n",
    "        sns.set(style=\"ticks\")\n",
    "        df_plot = pd.DataFrame(tr)\n",
    "        g = sns.PairGrid(df_plot)\n",
    "        g = g.map_upper(plt.scatter)\n",
    "        g = g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "        g = g.map_diag(sns.kdeplot, lw=3, legend=False)\n",
    "        g\n",
    "        \n",
    "    return tr, latent_dim, encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jitins_lab/anaconda2/envs/hyper/lib/python3.6/site-packages/ipykernel/__main__.py:63: UserWarning: Output \"dense_181\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"dense_181\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_175 (Dense)               (None, 9)            45          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_176 (Dense)               (None, 5)            50          dense_175[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_177 (Dense)               (None, 3)            18          dense_176[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_178 (Dense)               (None, 3)            18          dense_176[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 3)            0           dense_177[0][0]                  \n",
      "                                                                 dense_178[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_179 (Dense)               (None, 5)            20          lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_180 (Dense)               (None, 9)            54          dense_179[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_181 (Dense)               (None, 4)            40          dense_180[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 245\n",
      "Trainable params: 245\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 56.1658\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 33us/step - loss: 52.2223\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 34us/step - loss: 49.4908\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 31us/step - loss: 45.8053\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 33us/step - loss: 42.2506\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 41us/step - loss: 38.8209\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 38us/step - loss: 35.7067\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 32us/step - loss: 33.3874\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 43us/step - loss: 29.9289\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 52us/step - loss: 26.7847\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 51us/step - loss: 23.3023\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 52us/step - loss: 21.1021\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 38us/step - loss: 18.3457\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 42us/step - loss: 15.8949\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 37us/step - loss: 14.2520\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 35us/step - loss: 12.2429\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 41us/step - loss: 10.9251\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 35us/step - loss: 9.8512\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 35us/step - loss: 9.0670\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 41us/step - loss: 8.6851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-1.1596504 , -0.92211324, -0.6296273 ],\n",
       "        [-1.1672746 , -0.94965315, -0.59715897],\n",
       "        [-1.1029255 , -0.8750694 , -0.5854537 ],\n",
       "        [-1.1309884 , -0.897882  , -0.57688224],\n",
       "        [-1.1358716 , -0.8907459 , -0.6238425 ],\n",
       "        [-1.2461673 , -0.9778152 , -0.65713376],\n",
       "        [-1.1025052 , -0.8484813 , -0.5793726 ],\n",
       "        [-1.1693503 , -0.93064326, -0.619831  ],\n",
       "        [-1.0978465 , -0.87497944, -0.55111897],\n",
       "        [-1.162996  , -0.94648784, -0.6081832 ],\n",
       "        [-1.2082036 , -0.96418935, -0.6607308 ],\n",
       "        [-1.1539891 , -0.9081588 , -0.60489875],\n",
       "        [-1.135788  , -0.9287118 , -0.5952572 ],\n",
       "        [-1.0050159 , -0.7954196 , -0.54359055],\n",
       "        [-1.1956593 , -0.956868  , -0.6961391 ],\n",
       "        [-1.218105  , -0.9449584 , -0.69072086],\n",
       "        [-1.1842457 , -0.92383933, -0.65234125],\n",
       "        [-1.1735643 , -0.92746913, -0.6238568 ],\n",
       "        [-1.2957125 , -1.0359349 , -0.6822718 ],\n",
       "        [-1.1633693 , -0.9030027 , -0.63393253],\n",
       "        [-1.2696844 , -1.0255518 , -0.6531316 ],\n",
       "        [-1.1847153 , -0.9217159 , -0.62546617],\n",
       "        [-1.0096002 , -0.7514651 , -0.5779528 ],\n",
       "        [-1.2692959 , -1.0000367 , -0.6040179 ],\n",
       "        [-1.2016538 , -0.9475128 , -0.6089931 ],\n",
       "        [-1.2215207 , -0.99231106, -0.6066    ],\n",
       "        [-1.2128584 , -0.95390046, -0.60800254],\n",
       "        [-1.1929712 , -0.9535249 , -0.63909644],\n",
       "        [-1.183364  , -0.95235926, -0.6351027 ],\n",
       "        [-1.1556531 , -0.9161574 , -0.5900629 ],\n",
       "        [-1.180564  , -0.9464045 , -0.59450155],\n",
       "        [-1.2629205 , -1.0094967 , -0.63778144],\n",
       "        [-1.1294097 , -0.8683114 , -0.65700847],\n",
       "        [-1.1656321 , -0.90487665, -0.6779217 ],\n",
       "        [-1.162996  , -0.94648784, -0.6081832 ],\n",
       "        [-1.1293362 , -0.91489553, -0.6099858 ],\n",
       "        [-1.2041453 , -0.97849536, -0.6616693 ],\n",
       "        [-1.162996  , -0.94648784, -0.6081832 ],\n",
       "        [-1.0721303 , -0.8473675 , -0.55282086],\n",
       "        [-1.18536   , -0.94832706, -0.62799174],\n",
       "        [-1.1405619 , -0.8954137 , -0.61424595],\n",
       "        [-1.1516367 , -0.9556618 , -0.522805  ],\n",
       "        [-1.057737  , -0.8187566 , -0.558992  ],\n",
       "        [-1.2269557 , -0.95199436, -0.5978702 ],\n",
       "        [-1.2335265 , -0.9618434 , -0.6339969 ],\n",
       "        [-1.16717   , -0.93646556, -0.5816621 ],\n",
       "        [-1.1666282 , -0.91081655, -0.640577  ],\n",
       "        [-1.1054173 , -0.87073267, -0.57858336],\n",
       "        [-1.1920118 , -0.9464099 , -0.65267926],\n",
       "        [-1.1597896 , -0.9297443 , -0.6155274 ],\n",
       "        [-2.1887476 , -1.5967515 , -0.5648394 ],\n",
       "        [-2.0394611 , -1.4941893 , -0.5370222 ],\n",
       "        [-2.2215147 , -1.6066189 , -0.5335099 ],\n",
       "        [-1.944338  , -1.3992829 , -0.41343978],\n",
       "        [-2.1593065 , -1.552324  , -0.48276624],\n",
       "        [-1.9489539 , -1.4231253 , -0.48656943],\n",
       "        [-2.028491  , -1.4858751 , -0.53428304],\n",
       "        [-1.664979  , -1.2375333 , -0.45498258],\n",
       "        [-2.1403546 , -1.5553823 , -0.52605116],\n",
       "        [-1.793386  , -1.3121521 , -0.44893166],\n",
       "        [-1.7911762 , -1.3055782 , -0.40238342],\n",
       "        [-1.9331228 , -1.4150059 , -0.49742973],\n",
       "        [-2.0392082 , -1.4772747 , -0.45926422],\n",
       "        [-2.0508606 , -1.4897966 , -0.4978476 ],\n",
       "        [-1.7920539 , -1.3285277 , -0.5033432 ],\n",
       "        [-2.1056597 , -1.5391676 , -0.54578924],\n",
       "        [-1.9027544 , -1.3923843 , -0.48667127],\n",
       "        [-1.9099237 , -1.4118414 , -0.51839966],\n",
       "        [-2.206646  , -1.5525248 , -0.3873973 ],\n",
       "        [-1.8899772 , -1.3856542 , -0.47459114],\n",
       "        [-1.988701  , -1.4446621 , -0.48545364],\n",
       "        [-1.9730598 , -1.4443622 , -0.5039688 ],\n",
       "        [-2.2166934 , -1.5714946 , -0.43096805],\n",
       "        [-2.053051  , -1.4961596 , -0.5090604 ],\n",
       "        [-2.0577126 , -1.5032623 , -0.523634  ],\n",
       "        [-2.10417   , -1.5331666 , -0.529253  ],\n",
       "        [-2.2417822 , -1.6100945 , -0.50203913],\n",
       "        [-2.2286227 , -1.5955918 , -0.48803046],\n",
       "        [-2.0134244 , -1.4615021 , -0.48412445],\n",
       "        [-1.8244972 , -1.3565938 , -0.509838  ],\n",
       "        [-1.8744006 , -1.3714714 , -0.45865715],\n",
       "        [-1.8488891 , -1.3615985 , -0.47401667],\n",
       "        [-1.9039661 , -1.399085  , -0.49489114],\n",
       "        [-2.1393502 , -1.5246854 , -0.43792   ],\n",
       "        [-1.8582562 , -1.3622804 , -0.48077413],\n",
       "        [-1.9171213 , -1.4171593 , -0.53943694],\n",
       "        [-2.1521833 , -1.562531  , -0.5301332 ],\n",
       "        [-2.1741269 , -1.548708  , -0.43389207],\n",
       "        [-1.8359349 , -1.359261  , -0.5126634 ],\n",
       "        [-1.903147  , -1.3817079 , -0.44262385],\n",
       "        [-1.924895  , -1.4027786 , -0.4662007 ],\n",
       "        [-2.0171983 , -1.47332   , -0.5126827 ],\n",
       "        [-1.9375346 , -1.415976  , -0.4802328 ],\n",
       "        [-1.7040513 , -1.261466  , -0.44634926],\n",
       "        [-1.909843  , -1.3944292 , -0.47232547],\n",
       "        [-1.8609053 , -1.3804383 , -0.527056  ],\n",
       "        [-1.8905698 , -1.3911669 , -0.50248504],\n",
       "        [-2.013449  , -1.4735041 , -0.51742774],\n",
       "        [-1.6554587 , -1.2329495 , -0.46479273],\n",
       "        [-1.8983233 , -1.3925254 , -0.490045  ],\n",
       "        [-2.2490537 , -1.5849288 , -0.42347008],\n",
       "        [-2.1200852 , -1.4979577 , -0.39605057],\n",
       "        [-2.4580696 , -1.7214355 , -0.44411314],\n",
       "        [-2.238737  , -1.5881085 , -0.44731414],\n",
       "        [-2.3173554 , -1.6262829 , -0.41893864],\n",
       "        [-2.651055  , -1.8422945 , -0.4517851 ],\n",
       "        [-1.8730305 , -1.335849  , -0.36931884],\n",
       "        [-2.5469196 , -1.7840064 , -0.4666979 ],\n",
       "        [-2.4430854 , -1.6980364 , -0.3972203 ],\n",
       "        [-2.3998249 , -1.6986341 , -0.48682702],\n",
       "        [-2.177158  , -1.5581579 , -0.47476882],\n",
       "        [-2.279561  , -1.6013064 , -0.41016015],\n",
       "        [-2.3441265 , -1.6496456 , -0.4389335 ],\n",
       "        [-2.1380374 , -1.4945881 , -0.35152304],\n",
       "        [-2.1385167 , -1.4929535 , -0.35026282],\n",
       "        [-2.2018242 , -1.5600932 , -0.43589553],\n",
       "        [-2.2501624 , -1.6017103 , -0.46745092],\n",
       "        [-2.5093899 , -1.7896621 , -0.5575683 ],\n",
       "        [-2.8154047 , -1.9161654 , -0.370928  ],\n",
       "        [-2.2278101 , -1.5614786 , -0.37765464],\n",
       "        [-2.3612592 , -1.661998  , -0.4461922 ],\n",
       "        [-2.037546  , -1.4455824 , -0.3943705 ],\n",
       "        [-2.7230358 , -1.881383  , -0.4357349 ],\n",
       "        [-2.2005448 , -1.5568838 , -0.42211485],\n",
       "        [-2.2761993 , -1.6207395 , -0.47950238],\n",
       "        [-2.4218585 , -1.7211766 , -0.50982684],\n",
       "        [-2.1441593 , -1.5258825 , -0.4348073 ],\n",
       "        [-2.089639  , -1.5001156 , -0.4609979 ],\n",
       "        [-2.3087826 , -1.6150739 , -0.39955768],\n",
       "        [-2.4269047 , -1.7238941 , -0.5062376 ],\n",
       "        [-2.5779743 , -1.795713  , -0.44433165],\n",
       "        [-2.5076225 , -1.7982302 , -0.5860681 ],\n",
       "        [-2.316876  , -1.6159403 , -0.38768137],\n",
       "        [-2.1757534 , -1.5588827 , -0.47272944],\n",
       "        [-2.227473  , -1.582331  , -0.44597065],\n",
       "        [-2.6350627 , -1.8262832 , -0.43343773],\n",
       "        [-2.1749818 , -1.548068  , -0.45064217],\n",
       "        [-2.2049267 , -1.577538  , -0.4794943 ],\n",
       "        [-2.0552573 , -1.478009  , -0.45896426],\n",
       "        [-2.3335366 , -1.6487415 , -0.4563516 ],\n",
       "        [-2.334635  , -1.6353812 , -0.41546977],\n",
       "        [-2.3166199 , -1.6302128 , -0.43305215],\n",
       "        [-2.1200852 , -1.4979577 , -0.39605057],\n",
       "        [-2.360191  , -1.660357  , -0.44324055],\n",
       "        [-2.3087726 , -1.6249285 , -0.43309575],\n",
       "        [-2.30388   , -1.6160064 , -0.41338915],\n",
       "        [-2.2649493 , -1.5826645 , -0.37924397],\n",
       "        [-2.2327912 , -1.5831742 , -0.44509226],\n",
       "        [-2.1220834 , -1.5185719 , -0.46043962],\n",
       "        [-2.0676048 , -1.4843657 , -0.45484686]], dtype=float32),\n",
       " 3,\n",
       " <keras.engine.training.Model at 0x1a1c060668>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_feature_generation(df.iloc[:,:4],components='values',funnel=(9,5,3,3),epoch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible VAE latent features generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jitins_lab/anaconda2/envs/hyper/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Input, Lambda\n",
    "from keras.models import Model,Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import backend as K\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funnel[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_162 (Dense)            (None, 9)                 45        \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 5)                 50        \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 113\n",
      "Trainable params: 113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_165 (Dense)            (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 9)                 54        \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 4)                 40        \n",
      "=================================================================\n",
      "Total params: 114\n",
      "Trainable params: 114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Sequential)         (None, 3)                 113       \n",
      "_________________________________________________________________\n",
      "lambda_32 (Lambda)           (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "decoder (Sequential)         (None, 4)                 114       \n",
      "=================================================================\n",
      "Total params: 227\n",
      "Trainable params: 227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Tensor(\"decoder_target_13:0\", shape=(?, ?), dtype=float32) Tensor(\"decoder_21/dense_167/Elu:0\", shape=(?, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "original_dim = 4\n",
    "funnel=(9,5,3)\n",
    "\n",
    "mod_e = Sequential(name='encoder')\n",
    "mod_e.add(Dense(funnel[0], input_dim=original_dim))\n",
    "for i in funnel[1:]:\n",
    "    mod_e.add(Dense(i, activation='elu'))\n",
    "                \n",
    "mod_e.summary()\n",
    "z_mean = mod_e.output\n",
    "z_log_var = mod_e.output\n",
    "\n",
    "# batch_size = batch\n",
    "# epochs = epoch\n",
    "epsilon_std = 0.1\n",
    "\n",
    "def sampling(x,grps):\n",
    "    z_mean, z_log_var = grps\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], funnel[-1]), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(funnel[-1],),arguments={'grps':[z_mean, z_log_var]})\n",
    "    \n",
    "mod_d = Sequential(name='decoder')\n",
    "for i,v in enumerate(reversed(funnel[:-1])):\n",
    "    if i == 0:\n",
    "        mod_d.add(Dense(v, input_dim=funnel[-1],activation='elu'))\n",
    "    else:\n",
    "        mod_d.add(Dense(v, activation='elu'))\n",
    "# mod_d = Model(inputs=inp,outputs=z)\n",
    "mod_d.add(Dense(original_dim, activation='elu'))\n",
    "mod_d.summary()\n",
    "\n",
    "mod = Sequential()\n",
    "mod.add(mod_e)\n",
    "mod.add(z)\n",
    "mod.add(mod_d)\n",
    "mod.summary()\n",
    "\n",
    "def vae_loss(y_true, y_pred):\n",
    "#         x = K.flatten(x)\n",
    "#         x_decoded_mean = K.flatten(x_decoded_mean)\n",
    "    print(y_true,y_pred)    \n",
    "    xent_loss = original_dim * metrics.mean_squared_error(y_true, y_pred)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "mod.compile(optimizer='adam', loss=vae_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-1a2ca82258b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/hyper/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda2/envs/hyper/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/hyper/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[1;32m   1486\u001b[0m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/hyper/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                                                    self._feed_output_names)\n\u001b[1;32m   1485\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[0;32m-> 1486\u001b[0;31m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/hyper/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(y, sample_weight, class_weight, sample_weight_mode)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "mod.fit(df.iloc[:,:4].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_latent_feature(data,components='auto',funnel=(2.5,9),\n",
    "                           batch=200,epoch = 250,epsilon=1.0,opt= None,\n",
    "                           validation=False, plot_it=False):\n",
    "    \n",
    "    original_dim = data.shape[1]\n",
    "    \n",
    "    batch_size = batch\n",
    "    epochs = epoch\n",
    "    epsilon_std = epsilon\n",
    "    \n",
    "    # making encoder\n",
    "    mod_e = Sequential(name='encoder')\n",
    "    mod_e.add(Dense(funnel[0], input_dim=original_dim))\n",
    "    for i in funnel[1:]:\n",
    "        mod_e.add(Dense(i, activation='elu'))\n",
    "\n",
    "    mod_e.summary()\n",
    "    z_mean = mod_e.output\n",
    "    z_log_var = mod_e.output\n",
    "\n",
    "    def sampling(x,grps):\n",
    "        z_mean, z_log_var = grps\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], funnel[-1]), mean=0.,\n",
    "                                  stddev=epsilon_std)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    \n",
    "    # making sampling layer\n",
    "    z = Lambda(sampling, output_shape=(funnel[-1],),arguments={'grps':[z_mean, z_log_var]})\n",
    "    \n",
    "    #making decoder\n",
    "    mod_d = Sequential(name='decoder')\n",
    "    for i,v in enumerate(reversed(funnel[:-1])):\n",
    "        if i == 0:\n",
    "            mod_d.add(Dense(v, input_dim=funnel[-1],activation='elu'))\n",
    "        else:\n",
    "            mod_d.add(Dense(v, activation='elu'))\n",
    "    mod_d.add(Dense(original_dim, activation='elu'))\n",
    "    mod_d.summary()\n",
    "    \n",
    "    \n",
    "    # instantiate VAE model\n",
    "    vae = Sequential()\n",
    "    vae.add(mod_e)\n",
    "    vae.add(z)\n",
    "    vae.add(mod_d)\n",
    "\n",
    "    # Compute VAE loss\n",
    "#     xent_loss = original_dim * metrics.mean_squared_error(mod_e.get_layer(index=1).input, mod_d.get_output_at(len(mod_d.layers)-1))\n",
    "#     kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "#     vae_loss = K.mean(xent_loss + kl_loss)\n",
    "    \n",
    "    def vae_loss(y_true, y_pred):\n",
    "#         x = K.flatten(x)\n",
    "#         x_decoded_mean = K.flatten(x_decoded_mean)\n",
    "        xent_loss = original_dim * metrics.mean_squared_error(y_true, y_pred)\n",
    "        kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return xent_loss + kl_loss\n",
    "\n",
    "#     vae.add_loss(vae_loss)\n",
    "    if opt is None:\n",
    "        opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "    vae.compile(optimizer='adam', loss=vae_loss)\n",
    "    vae.summary()\n",
    "    \n",
    "    # fitting our generated features on the data\n",
    "    vae.fit(data,\n",
    "#             shuffle=True,\n",
    "            epochs=50,\n",
    "            batch_size=10\n",
    "    #         validation_data=(x_test, None)\n",
    "           )\n",
    "    \n",
    "    # Encoder model for feature generation\n",
    "    encoder = mod_e\n",
    "\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    tr = encoder.predict(data, batch_size=batch_size)\n",
    "    if plot_it:\n",
    "        print('\\nPlotting features!\\n')\n",
    "        # Plotting with SNS\n",
    "        sns.set(style=\"ticks\")\n",
    "        df_plot = pd.DataFrame(tr)\n",
    "        g = sns.PairGrid(df_plot)\n",
    "        g = g.map_upper(plt.scatter)\n",
    "        g = g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "        g = g.map_diag(sns.kdeplot, lw=3, legend=False)\n",
    "        g\n",
    "        \n",
    "    return tr, latent_dim, encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.054000           3.758667   \n",
       "std             0.828066          0.433594           1.764420   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.198667    1.000000  \n",
       "std            0.763161    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris()\n",
    "df  = pd.concat([pd.DataFrame(data.data),pd.DataFrame(data.target)],axis = 1)\n",
    "data.feature_names.append('target')\n",
    "df.columns = data.feature_names\n",
    "print(df.head())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_134 (Dense)            (None, 7)                 35        \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 2)                 16        \n",
      "=================================================================\n",
      "Total params: 51\n",
      "Trainable params: 51\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_136 (Dense)            (None, 7)                 21        \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 4)                 32        \n",
      "=================================================================\n",
      "Total params: 53\n",
      "Trainable params: 53\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Sequential)         (None, 2)                 51        \n",
      "_________________________________________________________________\n",
      "lambda_27 (Lambda)           (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "decoder (Sequential)         (None, 4)                 53        \n",
      "=================================================================\n",
      "Total params: 104\n",
      "Trainable params: 104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-df908bddc73d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae_latent_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfunnel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-4ffd160a53a0>\u001b[0m in \u001b[0;36mvae_latent_feature\u001b[0;34m(data, components, funnel, batch, epoch, epsilon, opt, validation, plot_it)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m#             shuffle=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;31m#         validation_data=(x_test, None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m            )\n",
      "\u001b[0;32m~/anaconda2/envs/hyper/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda2/envs/hyper/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/hyper/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[1;32m   1486\u001b[0m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/hyper/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                                                    self._feed_output_names)\n\u001b[1;32m   1485\u001b[0m         sample_weights = [_standardize_weights(ref, sw, cw, mode)\n\u001b[0;32m-> 1486\u001b[0;31m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/hyper/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(y, sample_weight, class_weight, sample_weight_mode)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "vae_latent_feature(data=df.iloc[:,0:4],funnel=(7,2),batch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hyper]",
   "language": "python",
   "name": "conda-env-hyper-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
