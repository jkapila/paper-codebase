{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TdbVV9bdx8uE"
   },
   "source": [
    "# The Staker......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJevGbGYx38-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, gc\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from warnings import warn\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, \\\n",
    "    f1_score\n",
    "from sklearn.metrics import roc_curve, cohen_kappa_score, log_loss, \\\n",
    "    adjusted_mutual_info_score\n",
    "from sklearn.metrics.regression import r2_score, mean_squared_error, \\\n",
    "    mean_absolute_error, explained_variance_score\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B2kqno5CyMEY"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston, load_breast_cancer, load_iris\n",
    "\n",
    "def get_data(dataname):\n",
    "    if dataname == 'iris':\n",
    "        data = load_iris()\n",
    "    elif dataname == 'boston':\n",
    "        data = load_boston()\n",
    "    elif dataname == 'cancer':\n",
    "        data = load_breast_cancer()\n",
    "    df = pd.concat([pd.DataFrame(data.data), pd.DataFrame(data.target)], axis=1)\n",
    "    names = [i for i in data.feature_names]\n",
    "    names.append('target')\n",
    "    df.columns = names\n",
    "    print(df.head())\n",
    "    print(df.describe())\n",
    "    return df\n",
    "\n",
    "\n",
    "def mape_1(y_true, y_pred):\n",
    "    abs_true = np.absolute(y_true)\n",
    "    abs_pred = np.absolute(y_true - y_pred)\n",
    "    n = y_true.shape[0]\n",
    "\n",
    "    return np.mean((abs_pred / abs_true)) * 100\n",
    "\n",
    "\n",
    "# todo:\n",
    "# 1) percentage concordant discordant\n",
    "# 2) kendal's tau\n",
    "# 3) gamma\n",
    "# 4) k\n",
    "objectives = {\n",
    "    'f1_score': f1_score,\n",
    "    'accuracy': accuracy_score,\n",
    "    'loss': log_loss,\n",
    "    'cohen_kappa': cohen_kappa_score,\n",
    "    'f1_score_multi': f1_score,\n",
    "    'accuracy_multi': accuracy_score,\n",
    "    'loss_multi': log_loss,\n",
    "    'cohen_kappa_multi': cohen_kappa_score,\n",
    "    '1_mape': mape_1,\n",
    "    'mse': mean_squared_error,\n",
    "    'mae': mean_absolute_error,\n",
    "    'mi': adjusted_mutual_info_score,\n",
    "    'kld': entropy\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBX01SoNyWzK"
   },
   "outputs": [],
   "source": [
    "class ModelBlender:\n",
    "\n",
    "    def __init__(self, problem='cls', training_ratio=0.7, blend_ratio=0.1,\n",
    "                 holdout_ratio=0.2, stack_levels=2,\n",
    "                 na_treatment='omit', sample_generation='random', shuffle=True,\n",
    "                 n_cross=1, seed=None, n_jobs=1):\n",
    "        \"\"\"\n",
    "\n",
    "        :param problem: cls(classification)(default), reg(regression) and clus(clustering),\n",
    "                        Type of problem to generate statistics.\n",
    "\n",
    "        :param training_ratio: 0 to 1, 0.7 (default), Ratio of training and\n",
    "                                blending data\n",
    "        :param blend_ratio: 0 to 1, 0.2 (default), Ratio to blend training data\n",
    "        :param holdout_ratio: 0 to 1, 0.2 (default), Ratio of blending  data\n",
    "\n",
    "        :param blended_samples: 2 (default), No of blending samples to make\n",
    "\n",
    "        :param stack_levels: 2 (default), Levels of stacking\n",
    "\n",
    "        :param na_treatment: 'omit'(default), 'impute', 'keep', 'keep_sep',\n",
    "                            omit: drop the nan rows in data\n",
    "                            impute: have to supply imputer/or imputtion function\n",
    "                                    with the data\n",
    "                            keep: will keep data as is\n",
    "                            keep_sep: will keep data separately and not process\n",
    "                                    in models\n",
    "\n",
    "        :param sample_generation:'random' (default), 'sequential'\n",
    "                            random: randomly sampling\n",
    "                            seq:  sequential splitting, need to pass column for splitting\n",
    "\n",
    "        :param shuffle: True(default), Boolean to indicate shuffling before\n",
    "                        modeling individual models\n",
    "\n",
    "        :param n_cross: Perform cross validation while model training\n",
    "\n",
    "        :param seed: Random Seed\n",
    "\n",
    "        :param n_jobs: 1 (default) Train and Score score in parallel fashion. Note individual\n",
    "                        model should be fed with linear processing, else training\n",
    "                        will not happen in sequential fashion only.\n",
    "\n",
    "        Note: Sum of training_ration,blend_ratio and hold_out ratio should ideally add\n",
    "              upto 1. If not training_ratio will be 1 - hold_out + blend_ration.\n",
    "        \"\"\"\n",
    "\n",
    "        self.problem = problem\n",
    "        self.training_ratio = training_ratio\n",
    "        self.blend_ratio = blend_ratio\n",
    "        self.holdout_ratio = holdout_ratio\n",
    "        self.stack_levels = stack_levels\n",
    "        self.na_treatment = na_treatment\n",
    "        self.sample_generation = sample_generation\n",
    "        self.shuffle = shuffle\n",
    "        self.n_cross = n_cross\n",
    "        self.seed = seed\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        if self.training_ratio + self.blend_ratio + self.holdout_ratio > 1:\n",
    "            self.training_ratio = 1 - self.blend_ratio + self.holdout_ratio\n",
    "\n",
    "        # data variables\n",
    "        self._train = None\n",
    "        self._blend = None\n",
    "        self._blend_out = None\n",
    "        self._hold_out = None\n",
    "        self._na_data = None\n",
    "        self._y_col = None\n",
    "\n",
    "        # model variables\n",
    "        self.modelstore = {'stack_{}'.format(i + 1): {} for i in\n",
    "                           range(self.stack_levels)}\n",
    "        self.stack_info = None\n",
    "        self.model_scores = None\n",
    "        # some basic stuff to do\n",
    "        # todo: set random seed\n",
    "        # todo: ensure n_jobs equal to 1 for sklearn model if n_jobs is -1\n",
    "        # todo: write more fuctions as metrics\n",
    "\n",
    "    def _get_metrics(self, y_true, y_pred, domain='Train', threshold=None):\n",
    "        if self.problem == 'cls':\n",
    "            y_cat_true = y_true\n",
    "            y_pred_cat = y_pred\n",
    "            fpr_test, tpr_test, thresholds_test = roc_curve(y_cat_true,\n",
    "                                                            y_pred_cat,\n",
    "                                                            pos_label=True)\n",
    "            sum_sensitivity_specificity_test = tpr_test + (1 - fpr_test)\n",
    "            best_threshold_id_test = np.argmax(sum_sensitivity_specificity_test)\n",
    "            best_threshold = thresholds_test[best_threshold_id_test]\n",
    "\n",
    "            if threshold is None:\n",
    "                y_test = np.array(y_pred_cat >= best_threshold, 'uint8')\n",
    "                threshold = best_threshold\n",
    "            else:\n",
    "                y_test = np.array(y_pred_cat >= threshold, 'uint8')\n",
    "\n",
    "            cm_test = confusion_matrix(y_cat_true, y_test)\n",
    "            acc_test = accuracy_score(y_cat_true, y_test)\n",
    "            auc_test = roc_auc_score(y_cat_true, y_test)\n",
    "            f1_score_test = f1_score(y_cat_true, y_test)\n",
    "\n",
    "            print('{} Threshold       : {}'.format(domain, threshold))\n",
    "            print('{} Cat. KLD        : {}'.format(domain, objectives['kld'](\n",
    "                y_cat_true.reshape(-1, 1), y_test.reshape(-1, 1))))\n",
    "            print('{} Accuracy        : {}'.format(domain,acc_test))\n",
    "            print('{} AUC             : {}'.format(domain, auc_test))\n",
    "            print('{} Cohe Kappa      : {}'.format(domain,\n",
    "                                                   objectives['cohen_kappa'](\n",
    "                                                       y_cat_true, y_test)))\n",
    "            print('{} Log Loss        : {}'.format(domain, objectives['loss'](\n",
    "                y_cat_true, y_test)))\n",
    "            print('{} F1 Score        : {}'.format(domain,\n",
    "                                                   objectives['f1_score'](\n",
    "                                                       y_cat_true, y_test)))\n",
    "            print('{} Confusion Matrix:'.format(domain))\n",
    "            print(cm_test)\n",
    "        elif self.problem == 'reg':\n",
    "            print('{} MAPE            : {}'.format(domain,\n",
    "                                                   objectives['1_mape'](y_true,\n",
    "                                                                        y_pred)))\n",
    "            print('{} MSE             : {}'.format(domain,\n",
    "                                                   objectives['mse'](y_true,\n",
    "                                                                     y_pred)))\n",
    "            print('{} MAE             : {}'.format(domain,\n",
    "                                                   objectives['mae'](y_true,\n",
    "                                                                     y_pred)))\n",
    "            print('{} Cont. KLD       : {}'.format(domain, objectives['kld'](\n",
    "                y_true.reshape(-1, 1), y_pred.reshape(-1, 1))))\n",
    "        elif self.problem == 'clus':\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def _get_prediction(self, model, X):\n",
    "\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            prob_pos = model.predict_proba(X)[:, 1]\n",
    "        else:  # use decision function\n",
    "            prob_pos = model.decision_function(X)\n",
    "            prob_pos = \\\n",
    "                (prob_pos - prob_pos.min()) / (\n",
    "                        prob_pos.max() - prob_pos.min())\n",
    "        return prob_pos\n",
    "\n",
    "    def _get_data(self, domain='Train', stack_level=None, namescope='title'):\n",
    "\n",
    "        if stack_level is None or stack_level == 0:\n",
    "            if domain == 'Train' or domain == 'train':\n",
    "                X = self._train.drop(self._y_col, axis=1)\n",
    "                y = self._train[self._y_col].values\n",
    "                name = domain.title() if namescope == 'title' else domain.lower()\n",
    "                return X, y, name\n",
    "\n",
    "            elif domain == 'blend' or domain == 'Blend':\n",
    "                X = self._blend.drop(self._y_col, axis=1)\n",
    "                y = self._blend[self._y_col].values\n",
    "                name = domain.title() if namescope == 'title' else domain.lower()\n",
    "                return X, y, name\n",
    "\n",
    "            elif domain == 'holdout' or domain == 'hold_out' or domain == 'Holdout':\n",
    "                X = self._hold_out.drop(self._y_col, axis=1)\n",
    "                y = self._hold_out[self._y_col].values\n",
    "                name = domain.title() if namescope == 'title' else domain.lower()\n",
    "                return X, y, name\n",
    "        else:\n",
    "            X, y, _ = self._get_data(domain=domain, stack_level=None)\n",
    "\n",
    "            models = self.modelstore['stack_{}'.format(stack_level)].items()\n",
    "            pred_df = pd.DataFrame(index=X.index)\n",
    "            for m_name, m_dict in models:\n",
    "                model = m_dict['model']\n",
    "                col_name = '{}_{}'.format(m_name, stack_level)\n",
    "                pred_df[col_name] = self._get_prediction(model, X)\n",
    "\n",
    "            X = pd.concat((X, pred_df), axis=1)\n",
    "            name = domain.title() if namescope == 'title' else domain.lower()\n",
    "            print('Stacking Done at level: {}'.format(stack_level))\n",
    "            return X, y, name\n",
    "\n",
    "    def _util_remove_dup(self, duplicate):\n",
    "        final_list = []\n",
    "        dups = []\n",
    "        for num in duplicate:\n",
    "            if num not in final_list:\n",
    "                final_list.append(num)\n",
    "            else:\n",
    "                dups.append(num)\n",
    "        # print(dups)\n",
    "        return final_list\n",
    "\n",
    "    def _plot_calibration(self, stack_level=1, domain='train'):\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "        ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "        X, y, _data_name = self._get_data(domain, stack_level=stack_level)\n",
    "        ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "        for name, m_dict in self.modelstore[\n",
    "            'stack_{}'.format(stack_level)].items():\n",
    "            clf = m_dict['model']\n",
    "            cols = m_dict['columns']\n",
    "            prob_pos = self._get_prediction(clf, X[cols])\n",
    "            fraction_of_positives, mean_predicted_value = \\\n",
    "                calibration_curve(y, prob_pos, n_bins=10)\n",
    "\n",
    "            ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "                     label=\"%s\" % (name,))\n",
    "\n",
    "            ax2.hist(prob_pos, range=(0, 1), bins=10, label=name,\n",
    "                     histtype=\"step\", lw=2)\n",
    "\n",
    "        ax1.set_ylabel(\"Fraction of positives\")\n",
    "        ax1.set_ylim([-0.05, 1.05])\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "        ax1.set_title(\n",
    "            'Calibration plots (reliability curve) for {} Data'.format(\n",
    "                _data_name))\n",
    "\n",
    "        ax2.set_xlabel(\"Mean predicted value\")\n",
    "        ax2.set_ylabel(\"Count\")\n",
    "        ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def fit_data(self, df, na_imputation=None, seq_column=None):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        :param df: A Pandas Dataframe\n",
    "        :param na_imputation: Imputer function\n",
    "        :param seq_column: Sequential column\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        X = df.copy(deep=True)\n",
    "        shp = X.shape\n",
    "        if na_imputation is None and self.na_treatment == 'impute':\n",
    "            warn('Imputer not supplied! Will keep the data separately!')\n",
    "            self._na_data = X[X.isnull().any(axis=1)]\n",
    "            X.dropna(inplace=True)\n",
    "        elif self.na_treatment == 'impute':\n",
    "            X = na_imputation(X)\n",
    "        elif self.na_treatment == 'omit':\n",
    "            X.dropna(inplace=True)\n",
    "        elif self.na_treatment == 'keep_sep':\n",
    "            self._na_data = X[X.isnull().any(axis=1)]\n",
    "            X.dropna(inplace=True)\n",
    "        elif self.na_treatment == 'keep':\n",
    "            pass\n",
    "\n",
    "        if self.sample_generation == 'seq' and seq_column is None:\n",
    "            warn('Column for sequential not supplied! Will do random sampling!')\n",
    "            pass\n",
    "        elif self.sample_generation == 'seq':\n",
    "            pass\n",
    "        else:\n",
    "            self._hold_out = X.sample(frac=self.holdout_ratio,\n",
    "                                      random_state=self.seed)\n",
    "            X.drop(self._hold_out.index, inplace=True)\n",
    "            self._train = X.sample(frac=self.training_ratio,\n",
    "                                   random_state=self.seed)\n",
    "            X.drop(self._train.index, inplace=True)\n",
    "\n",
    "            indexes = self._train.index\n",
    "            n_blend = int(np.ceil(self.blend_ratio * shp[0]))\n",
    "\n",
    "            part = np.random.choice(indexes, size=n_blend,\n",
    "                                    replace=False)\n",
    "            blend = self._train.drop(part)\n",
    "            blend = pd.concat((blend, X), axis=0)\n",
    "            # blend = self._train.copy(deep=True)\n",
    "            # blend.loc[part] = X\n",
    "            self._blend = blend.copy(deep=True)\n",
    "            del blend\n",
    "            gc.collect()\n",
    "            self._blend_out = X\n",
    "\n",
    "        print('Data Splitting Summary:')\n",
    "        print('Input Shape    : {} {}'.format(df.shape,\n",
    "                                              np.sum(np.isnan(df.values))))\n",
    "        print('Training Shape : {} {}'.format(self._train.shape,\n",
    "                                              np.sum(np.isnan(\n",
    "                                                  self._train.values))))\n",
    "        print('Blend Shape    : {} {}'.format(self._blend.shape,\n",
    "                                              np.sum(np.isnan(\n",
    "                                                  self._blend.values))))\n",
    "        print('Hold Out Shape : {} {}'.format(self._hold_out.shape,\n",
    "                                              np.sum(np.isnan(\n",
    "                                                  self._hold_out.values))))\n",
    "\n",
    "    def fit_model(self, model_list, y_col, stack_level=None, threshold=None):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        :param model_list: list to models to train on [(name,est)]\n",
    "        :param y_col: target variable\n",
    "        :param stack_level: stack_level at which model is to be trained\n",
    "        :param threshold: threshold for classifier\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if y_col not in self._train.columns:\n",
    "            raise ValueError('{} is not in fitted data!'.format(y_col))\n",
    "        else:\n",
    "            if self._y_col is None:\n",
    "                self._y_col = y_col\n",
    "            else:\n",
    "                print(\n",
    "                    'Depedent Variable changed from \\'{}\\' to \\'{}\\' !'.format(\n",
    "                        self._y_col, y_col))\n",
    "                self._y_col = y_col\n",
    "\n",
    "        if stack_level is None and self.stack_info is None:\n",
    "            self.stack_info = 1\n",
    "            stack_level = 1\n",
    "\n",
    "        if isinstance(model_list, list):  # or isinstance(model_list, tuple):\n",
    "            n_models = len(model_list)\n",
    "            print('{} models to _train on training dataset'.format(n_models))\n",
    "            for m_name, m_est in model_list:\n",
    "                print('Training for model no.: {}'.format(m_name))\n",
    "                X, y, _ = self._get_data('train')\n",
    "                cols = X.columns\n",
    "                m_est.fit(X, y)\n",
    "                pred = m_est.predict(X)\n",
    "                self._get_metrics(y, pred,\n",
    "                                  domain='Model {} Training'.format(m_name),\n",
    "                                  threshold=threshold)\n",
    "\n",
    "                X, y, _ = self._get_data('blend')\n",
    "                pred = m_est.predict(X)\n",
    "                self._get_metrics(y, pred,\n",
    "                                  domain='Model {} on Blended'.format(m_name),\n",
    "                                  threshold=threshold)\n",
    "\n",
    "                self.modelstore['stack_{}'.format(stack_level)][m_name] \\\n",
    "                    = {'model': m_est, 'columns': cols, 'level': 1}\n",
    "\n",
    "        self._plot_calibration(stack_level=1, domain='train')\n",
    "        self._plot_calibration(stack_level=1, domain='blend')\n",
    "\n",
    "    def stack_train(self, model_list, stack_level, threshold=None):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        :param model_list: a list of tuples of [(name, estimator, columns)]\n",
    "        :param model_config:\n",
    "        :param stack_level: Level at which stacking need to be done.\n",
    "        :return:\n",
    "         Note before any training all previous stacking steps will be done.\n",
    "         The nomenclature of columns to be used for stacking should be of\n",
    "         consumed for either get_variable_name() or '{}_{}_{}'.format(\n",
    "         name of estimator,stack_level,type of data)\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(model_list, list):\n",
    "            X, y, _ = self._get_data('blend', stack_level)\n",
    "            X_hold, y_hold, _ = self._get_data('hold_out', stack_level)\n",
    "            for m_name, m_est, m_col in model_list:\n",
    "                if len(m_col) == 0:\n",
    "                    print('All columns will be used to fit {} model'.format(\n",
    "                        m_name))\n",
    "                    m_col = X.columns\n",
    "                elif np.any([True if i in X.columns else False for i in m_col]):\n",
    "                    raise ValueError('Few columns of {} are not in {}'.format(\n",
    "                        m_col, X.columns))\n",
    "\n",
    "                m_est.fit(X[m_col], y)\n",
    "                pred = m_est.predict(X[m_col])\n",
    "                self._get_metrics(y, pred,\n",
    "                                  domain='Model {} Blended'.format(m_name),\n",
    "                                  threshold=threshold)\n",
    "\n",
    "                pred = m_est.predict(X_hold[m_col])\n",
    "                self._get_metrics(y_hold, pred,\n",
    "                                  domain='Model {} on Hold_out'.format(m_name),\n",
    "                                  threshold=threshold)\n",
    "\n",
    "                self.modelstore['stack_{}'.format(stack_level + 1)][m_name] \\\n",
    "                    = {'model': m_est, 'columns': m_col, 'level': 2}\n",
    "\n",
    "        # self._plot_calibration(stack_level=1, domain='blend')\n",
    "        # self._plot_calibration(stack_level=2, domain='holdout')\n",
    "\n",
    "    def reblend(self):\n",
    "        indexes = self._train.index\n",
    "        shp = self._blend_out\n",
    "        part = np.random.choice(indexes, size=int(shp[0]),\n",
    "                                replace=False)\n",
    "        blend = self._train.drop(part)\n",
    "        blend = pd.concat((blend, self._blend_out), axis=0)\n",
    "        # blend = self._train.copy(deep=True)\n",
    "        # blend.loc[part] = X\n",
    "        self._blend = blend.copy(deep=True)\n",
    "        del blend\n",
    "        gc.collect()\n",
    "\n",
    "    def get_variable_name(self, stack_level):\n",
    "        cols = []\n",
    "        for i in self.modelstore['stack_{}'.format(stack_level)].keys():\n",
    "            col = self.modelstore['stack_{}'.format(stack_level)][i]['columns']\n",
    "            cols.extend(col)\n",
    "\n",
    "        return self._util_remove_dup(cols)\n",
    "\n",
    "    def plot_model(self, stack_level=None):\n",
    "        pass\n",
    "\n",
    "    def plot_scores(self, stack_level=None):\n",
    "        pass\n",
    "\n",
    "    def generate_stack(self, domain, stack_level=None):\n",
    "        X, y, _ = self._get_data(domain, stack_level)\n",
    "        return X, y\n",
    "\n",
    "    def save(self):\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self, stack_level=None):\n",
    "        pass\n",
    "\n",
    "    def score_on_holdout(self, stack_level=None, threshold=None):\n",
    "        if stack_level is None:\n",
    "            for stack in self.modelstore.keys():\n",
    "                for m_name, m_dict in self.modelstore[stack].items():\n",
    "                    # print(m_name)\n",
    "                    # print(m_dict)\n",
    "                    lvl = int(m_dict['level'])\n",
    "                    m_est = m_dict['model']\n",
    "                    m_col = m_dict['columns']\n",
    "                    X, y, _ = self._get_data('holdout', lvl - 1)\n",
    "\n",
    "                    pred = m_est.predict(X[m_col])\n",
    "                    self._get_metrics(y, pred,\n",
    "                                      domain='Model {} on Hold Out'.format(\n",
    "                                          m_name),\n",
    "                                      threshold=threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mhKKZbvyduX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pFAinWrYyeLT"
   },
   "source": [
    "### Lets use it...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBnVoMsPybHY"
   },
   "outputs": [],
   "source": [
    "# X = np.random.random((1000,10))\n",
    "# X = get_data('boston')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3386
    },
    "colab_type": "code",
    "id": "t-3ZzBk1yl2C",
    "outputId": "361cf252-6800-4245-a023-f47e2793fb5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Splitting Summary:\n",
      "Input Shape    : (50000, 51) 0\n",
      "Training Shape : (28000, 51) 0\n",
      "Blend Shape    : (35000, 51) 0\n",
      "Hold Out Shape : (10000, 51) 0\n",
      "4 models to _train on training dataset\n",
      "Training for model no.: lr\n",
      "Model lr Training Threshold       : 1\n",
      "Model lr Training Cat. KLD        : [inf]\n",
      "Model lr Training Accuracy        : 0.6786428571428571\n",
      "Model lr Training AUC             : 0.6786025037870071\n",
      "Model lr Training Cohe Kappa      : 0.3572327843731622\n",
      "Model lr Training Log Loss        : 11.099403724732054\n",
      "Model lr Training F1 Score        : 0.6719889180519102\n",
      "Model lr Training Confusion Matrix:\n",
      "[[9785 4245]\n",
      " [4753 9217]]\n",
      "Model lr on Blended Threshold       : 1\n",
      "Model lr on Blended Cat. KLD        : [inf]\n",
      "Model lr on Blended Accuracy        : 0.6809142857142857\n",
      "Model lr on Blended AUC             : 0.6808376985603124\n",
      "Model lr on Blended Cohe Kappa      : 0.36172678743222153\n",
      "Model lr on Blended Log Loss        : 11.020950898582244\n",
      "Model lr on Blended F1 Score        : 0.6740031525483099\n",
      "Model lr on Blended Confusion Matrix:\n",
      "[[12287  5286]\n",
      " [ 5882 11545]]\n",
      "Training for model no.: gnb\n",
      "Model gnb Training Threshold       : 1\n",
      "Model gnb Training Cat. KLD        : [inf]\n",
      "Model gnb Training Accuracy        : 0.7093928571428572\n",
      "Model gnb Training AUC             : 0.7093123131687848\n",
      "Model gnb Training Cohe Kappa      : 0.41869095497965103\n",
      "Model gnb Training Log Loss        : 10.037316531995101\n",
      "Model gnb Training F1 Score        : 0.6975655082698382\n",
      "Model gnb Training Confusion Matrix:\n",
      "[[10479  3551]\n",
      " [ 4586  9384]]\n",
      "Model gnb on Blended Threshold       : 1\n",
      "Model gnb on Blended Cat. KLD        : [inf]\n",
      "Model gnb on Blended Accuracy        : 0.7080857142857143\n",
      "Model gnb on Blended AUC             : 0.7079234286496368\n",
      "Model gnb on Blended Cohe Kappa      : 0.41597764566348316\n",
      "Model gnb on Blended Log Loss        : 10.082463881021985\n",
      "Model gnb on Blended F1 Score        : 0.6953332339346951\n",
      "Model gnb on Blended Confusion Matrix:\n",
      "[[13124  4449]\n",
      " [ 5768 11659]]\n",
      "Training for model no.: svc\n",
      "Model svc Training Threshold       : 1\n",
      "Model svc Training Cat. KLD        : [inf]\n",
      "Model svc Training Accuracy        : 0.5745714285714286\n",
      "Model svc Training AUC             : 0.5745365667495411\n",
      "Model svc Training Cohe Kappa      : 0.14908294563596824\n",
      "Model svc Training Log Loss        : 14.693946246607958\n",
      "Model svc Training F1 Score        : 0.5669938204289349\n",
      "Model svc Training Confusion Matrix:\n",
      "[[8289 5741]\n",
      " [6171 7799]]\n",
      "Model svc on Blended Threshold       : 1\n",
      "Model svc on Blended Cat. KLD        : [inf]\n",
      "Model svc on Blended Accuracy        : 0.5782285714285714\n",
      "Model svc on Blended AUC             : 0.578161639260002\n",
      "Model svc on Blended Cohe Kappa      : 0.15634191224766503\n",
      "Model svc on Blended Log Loss        : 14.567631973455605\n",
      "Model svc on Blended F1 Score        : 0.5702974908307621\n",
      "Model svc on Blended Confusion Matrix:\n",
      "[[10442  7131]\n",
      " [ 7631  9796]]\n",
      "Training for model no.: rfc\n",
      "Model rfc Training Threshold       : 1\n",
      "Model rfc Training Cat. KLD        : [inf]\n",
      "Model rfc Training Accuracy        : 0.9999642857142857\n",
      "Model rfc Training AUC             : 0.9999642090193271\n",
      "Model rfc Training Cohe Kappa      : 0.9999285710896485\n",
      "Model rfc Training Log Loss        : 0.0012335277283906665\n",
      "Model rfc Training F1 Score        : 0.999964207738287\n",
      "Model rfc Training Confusion Matrix:\n",
      "[[14030     0]\n",
      " [    1 13969]]\n",
      "Model rfc on Blended Threshold       : 1\n",
      "Model rfc on Blended Cat. KLD        : [inf]\n",
      "Model rfc on Blended Accuracy        : 0.9831714285714286\n",
      "Model rfc on Blended AUC             : 0.9831648188908404\n",
      "Model rfc on Blended Cohe Kappa      : 0.9663418462442506\n",
      "Model rfc on Blended Log Loss        : 0.5812443882489633\n",
      "Model rfc on Blended F1 Score        : 0.9830751989885349\n",
      "Model rfc on Blended Confusion Matrix:\n",
      "[[17305   268]\n",
      " [  321 17106]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "Stacking Done at level: 1\n",
      "Stacking Done at level: 1\n",
      "All columns will be used to fit lr2 model\n",
      "Model lr2 Blended Threshold       : 1\n",
      "Model lr2 Blended Cat. KLD        : [inf]\n",
      "Model lr2 Blended Accuracy        : 0.9845428571428572\n",
      "Model lr2 Blended AUC             : 0.9845429457285152\n",
      "Model lr2 Blended Cohe Kappa      : 0.9690851984501684\n",
      "Model lr2 Blended Log Loss        : 0.5338770148613635\n",
      "Model lr2 Blended F1 Score        : 0.9844794445878876\n",
      "Model lr2 Blended Confusion Matrix:\n",
      "[[17301   272]\n",
      " [  269 17158]]\n",
      "Model lr2 on Hold_out Threshold       : 1\n",
      "Model lr2 on Hold_out Cat. KLD        : [inf]\n",
      "Model lr2 on Hold_out Accuracy        : 0.9525\n",
      "Model lr2 on Hold_out AUC             : 0.9525466874564745\n",
      "Model lr2 on Hold_out Cohe Kappa      : 0.9049980847613888\n",
      "Model lr2 on Hold_out Log Loss        : 1.6406089901432643\n",
      "Model lr2 on Hold_out F1 Score        : 0.9528067560854446\n",
      "Model lr2 on Hold_out Confusion Matrix:\n",
      "[[4730  214]\n",
      " [ 261 4795]]\n",
      "All columns will be used to fit rfc model\n",
      "Model rfc Blended Threshold       : 1\n",
      "Model rfc Blended Cat. KLD        : [inf]\n",
      "Model rfc Blended Accuracy        : 0.9999428571428571\n",
      "Model rfc Blended AUC             : 0.9999426177770127\n",
      "Model rfc Blended Cohe Kappa      : 0.9998857122425291\n",
      "Model rfc Blended Log Loss        : 0.0019736443654244664\n",
      "Model rfc Blended F1 Score        : 0.9999426144841042\n",
      "Model rfc Blended Confusion Matrix:\n",
      "[[17573     0]\n",
      " [    2 17425]]\n",
      "Model rfc on Hold_out Threshold       : 1\n",
      "Model rfc on Hold_out Cat. KLD        : [inf]\n",
      "Model rfc on Hold_out Accuracy        : 0.9569\n",
      "Model rfc on Hold_out AUC             : 0.9569382783376348\n",
      "Model rfc on Hold_out Cohe Kappa      : 0.9137967173789978\n",
      "Model rfc on Hold_out Log Loss        : 1.4886369347302828\n",
      "Model rfc on Hold_out F1 Score        : 0.9572123498461234\n",
      "Model rfc on Hold_out Confusion Matrix:\n",
      "[[4748  196]\n",
      " [ 235 4821]]\n",
      "Model lr on Hold Out Threshold       : 1\n",
      "Model lr on Hold Out Cat. KLD        : [inf]\n",
      "Model lr on Hold Out Accuracy        : 0.6769\n",
      "Model lr on Hold Out AUC             : 0.6772257511982304\n",
      "Model lr on Hold Out Cohe Kappa      : 0.3541920312693383\n",
      "Model lr on Hold Out Log Loss        : 11.159594754742505\n",
      "Model lr on Hold Out F1 Score        : 0.6698007153806848\n",
      "Model lr on Hold Out Confusion Matrix:\n",
      "[[3492 1452]\n",
      " [1779 3277]]\n",
      "Model gnb on Hold Out Threshold       : 1\n",
      "Model gnb on Hold Out Cat. KLD        : [inf]\n",
      "Model gnb on Hold Out Accuracy        : 0.7035\n",
      "Model gnb on Hold Out AUC             : 0.7040172719265905\n",
      "Model gnb on Hold Out Cohe Kappa      : 0.4075825596141778\n",
      "Model gnb on Hold Out Log Loss        : 10.240845951373649\n",
      "Model gnb on Hold Out F1 Score        : 0.6916917957783092\n",
      "Model gnb on Hold Out Confusion Matrix:\n",
      "[[3709 1235]\n",
      " [1730 3326]]\n",
      "Model svc on Hold Out Threshold       : 1\n",
      "Model svc on Hold Out Cat. KLD        : [inf]\n",
      "Model svc on Hold Out Accuracy        : 0.5717\n",
      "Model svc on Hold Out AUC             : 0.5718938183605752\n",
      "Model svc on Hold Out Cohe Kappa      : 0.1437164823881093\n",
      "Model svc on Hold Out Log Loss        : 14.793120328178318\n",
      "Model svc on Hold Out F1 Score        : 0.5669800829036499\n",
      "Model svc on Hold Out Confusion Matrix:\n",
      "[[2913 2031]\n",
      " [2252 2804]]\n",
      "Model rfc on Hold Out Threshold       : 1\n",
      "Model rfc on Hold Out Cat. KLD        : [inf]\n",
      "Model rfc on Hold Out Accuracy        : 0.9522\n",
      "Model rfc on Hold Out AUC             : 0.9523015367047643\n",
      "Model rfc on Hold Out Cohe Kappa      : 0.9044085649925767\n",
      "Model rfc on Hold Out Log Loss        : 1.6509687839876481\n",
      "Model rfc on Hold Out F1 Score        : 0.952276357827476\n",
      "Model rfc on Hold Out Confusion Matrix:\n",
      "[[4753  191]\n",
      " [ 287 4769]]\n",
      "Stacking Done at level: 1\n",
      "Model lr2 on Hold Out Threshold       : 1\n",
      "Model lr2 on Hold Out Cat. KLD        : [inf]\n",
      "Model lr2 on Hold Out Accuracy        : 0.9525\n",
      "Model lr2 on Hold Out AUC             : 0.9525466874564745\n",
      "Model lr2 on Hold Out Cohe Kappa      : 0.9049980847613888\n",
      "Model lr2 on Hold Out Log Loss        : 1.6406089901432643\n",
      "Model lr2 on Hold Out F1 Score        : 0.9528067560854446\n",
      "Model lr2 on Hold Out Confusion Matrix:\n",
      "[[4730  214]\n",
      " [ 261 4795]]\n",
      "Stacking Done at level: 1\n",
      "Model rfc on Hold Out Threshold       : 1\n",
      "Model rfc on Hold Out Cat. KLD        : [inf]\n",
      "Model rfc on Hold Out Accuracy        : 0.9569\n",
      "Model rfc on Hold Out AUC             : 0.9569382783376348\n",
      "Model rfc on Hold Out Cohe Kappa      : 0.9137967173789978\n",
      "Model rfc on Hold Out Log Loss        : 1.4886369347302828\n",
      "Model rfc on Hold Out F1 Score        : 0.9572123498461234\n",
      "Model rfc on Hold Out Confusion Matrix:\n",
      "[[4748  196]\n",
      " [ 235 4821]]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=50000, n_features=50,\n",
    "                           n_informative=10, n_redundant=10,\n",
    "                           n_clusters_per_class=2,n_repeated=5,shift=1.0,\n",
    "                           scale=2, random_state=5454, shuffle=True)\n",
    "# clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "#                              random_state=0)\n",
    "# clf.fit(X, y)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df['target'] = y\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr2 = LogisticRegression(solver='lbfgs')\n",
    "gnb = GaussianNB()\n",
    "svc = LinearSVC(C=1.0)\n",
    "rfc = RandomForestClassifier(n_estimators=50)\n",
    "rfc2 = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "stacker = ModelBlender()\n",
    "stacker.fit_data(df)\n",
    "stacker.fit_model([('lr', lr), ('gnb', gnb), ('svc', svc),('rfc', rfc)],\n",
    "                  y_col='target')\n",
    "# print(stacker.get_variable_name(1))\n",
    "# print(stacker.modelstore)\n",
    "stacker.stack_train([('lr2', lr2, []), ('rfc', rfc2, [])], stack_level=1)\n",
    "# print(stacker.modelstore)\n",
    "stacker.score_on_holdout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQ4Pm-Sd4KGz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "The Stacker V1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
